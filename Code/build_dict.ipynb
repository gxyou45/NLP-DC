{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from text_cleaner import remove\n",
    "from text_cleaner.processor.common import ASCII, SYMBOLS_AND_PUNCTUATION_EXTENSION, GENERAL_PUNCTUATION\n",
    "from text_cleaner.processor.chinese import CHINESE, CHINESE_SYMBOLS_AND_PUNCTUATION\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\n",
    "        u'(\\U0001F1F2\\U0001F1F4)|'       # Macau flag\n",
    "        u'([\\U0001F1E6-\\U0001F1FF]{2})|' # flags\n",
    "        u'([\\U0001F600-\\U0001F64F])'     # emoticons\n",
    "        \"+\", flags=re.UNICODE)\n",
    "en_pattern = \"[a-zA-Z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    new_str = ''\n",
    "    for i in s:\n",
    "        # remove emoji\n",
    "        if i not in emoji.UNICODE_EMOJI:\n",
    "            new_str = new_str+i\n",
    "    new_str = emoji_pattern.sub('', new_str)\n",
    "    new_str = re.sub(en_pattern,'', new_str)\n",
    "    new_str = SYMBOLS_AND_PUNCTUATION_EXTENSION.remove(new_str)\n",
    "    new_str = GENERAL_PUNCTUATION.remove(new_str)\n",
    "    new_str = CHINESE_SYMBOLS_AND_PUNCTUATION.remove(new_str)\n",
    "    new_str = ' '.join(new_str.split())\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🇩🇪-消防车🚒//@app菌:哈哈哈哈哈哈哈哈 谈个恋爱还不够生气的//@一个阿呆仔:学猪叫那个真笑出猪声[允悲]//@梨 园西池水: 哈哈哈哈哈哈哈哈哈哈//@太皇太后您有喜啦:哈哈哈哈哈哈哈哈哈怎么这么好笑ˊ_>ˋ\n"
     ]
    }
   ],
   "source": [
    "s = \"🇩🇪-消防车🚒//@app菌:哈哈哈哈哈哈哈哈 谈个恋爱还不够生气的//@一个阿呆仔:学猪叫那个真笑出猪声[允悲]//@梨 园西池水: 哈哈哈哈哈哈哈哈哈哈//@太皇太后您有喜啦:哈哈哈哈哈哈哈哈哈怎么这么好笑ˊ_>ˋ\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "消防车 菌 哈哈哈哈哈哈哈哈 谈个恋爱还不够生气的 一个阿呆仔 学猪叫那个真笑出猪声 允悲 梨 园西池水 哈哈哈哈哈哈哈哈哈哈 太皇太后您有喜啦 哈哈哈哈哈哈哈哈哈怎么这么好笑ˊ ˋ\n"
     ]
    }
   ],
   "source": [
    "s = preprocess(s)\n",
    "maxlen = 5\n",
    "seqlen = len(s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(s):\n",
    "    words = []\n",
    "    slist = s.split(' ')\n",
    "    # print(slist)\n",
    "    for segment in slist:\n",
    "        segment = \"$\" + segment + \"$\"\n",
    "#        for i, char in enumerate(segment):\n",
    "#             for j in range(i+1, i+maxlen+1):\n",
    "#                 if j > len(segment):\n",
    "#                     break\n",
    "#                 w = segment[i:j]\n",
    "#                 print(\"1:\",w)\n",
    "#                 words.append(w) \n",
    "        for j in range(1, len(segment)-1):\n",
    "            w = segment[j: min(maxlen + j,  len(segment))]\n",
    "            words.append(w) \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['消防车$', '防车$', '车$', '菌$', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈$', '哈哈哈$', '哈哈$', '哈$', '谈个恋爱还', '个恋爱还不', '恋爱还不够', '爱还不够生', '还不够生气', '不够生气的', '够生气的$', '生气的$', '气的$', '的$', '一个阿呆仔', '个阿呆仔$', '阿呆仔$', '呆仔$', '仔$', '学猪叫那个', '猪叫那个真', '叫那个真笑', '那个真笑出', '个真笑出猪', '真笑出猪声', '笑出猪声$', '出猪声$', '猪声$', '声$', '允悲$', '悲$', '梨$', '园西池水$', '西池水$', '池水$', '水$', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈$', '哈哈哈$', '哈哈$', '哈$', '太皇太后您', '皇太后您有', '太后您有喜', '后您有喜啦', '您有喜啦$', '有喜啦$', '喜啦$', '啦$', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈怎', '哈哈哈怎么', '哈哈怎么这', '哈怎么这么', '怎么这么好', '么这么好笑', '这么好笑ˊ', '么好笑ˊ$', '好笑ˊ$', '笑ˊ$', 'ˊ$', 'ˋ$']\n"
     ]
    }
   ],
   "source": [
    "segmentList = get_segment(s)\n",
    "print(segmentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counterMap = {}\n",
    "# for seg in segmentList:\n",
    "#     if seg in counterMap.keys():\n",
    "#         counterMap[seg] += 1\n",
    "#     else:\n",
    "#         counterMap[seg] = 1\n",
    "# print(counterMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ˊ$', 'ˋ$', '一个阿呆仔', '不够生气的', '个恋爱还不', '个真笑出猪', '个阿呆仔$', '么好笑ˊ$', '么这么好笑', '仔$', '允悲$', '出猪声$', '叫那个真笑', '后您有喜啦', '呆仔$', '哈$', '哈$', '哈哈$', '哈哈$', '哈哈哈$', '哈哈哈$', '哈哈哈哈$', '哈哈哈哈$', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈怎', '哈哈哈怎么', '哈哈怎么这', '哈怎么这么', '啦$', '喜啦$', '园西池水$', '声$', '够生气的$', '太后您有喜', '太皇太后您', '好笑ˊ$', '学猪叫那个', '怎么这么好', '恋爱还不够', '您有喜啦$', '悲$', '有喜啦$', '梨$', '气的$', '水$', '池水$', '消防车$', '爱还不够生', '猪叫那个真', '猪声$', '生气的$', '的$', '皇太后您有', '真笑出猪声', '笑ˊ$', '笑出猪声$', '菌$', '西池水$', '谈个恋爱还', '车$', '还不够生气', '这么好笑ˊ', '那个真笑出', '防车$', '阿呆仔$']\n"
     ]
    }
   ],
   "source": [
    "ngramsort = sorted(segmentList)\n",
    "print(ngramsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRight(ngramsort):\n",
    "    outpath = \"freqright.data\"\n",
    "    sys.stdout = open(outpath, 'wt')\n",
    "    ngram = \"\"\n",
    "    pause = False\n",
    "    sameWord = []\n",
    "    for curr in ngramsort:\n",
    "    #     print(\"curr\", curr)\n",
    "        if pause:\n",
    "            break\n",
    "        if ngram == \"\":\n",
    "            sameWord.append(curr)\n",
    "            ngram = curr\n",
    "        else:\n",
    "            if curr.startswith(ngram):\n",
    "                sameWord.append(curr)\n",
    "    #             print(\"1\",sameWord)\n",
    "            else:\n",
    "                if not sameWord: # sameword is empty\n",
    "                    pause = False\n",
    "                    sameWord.append(curr)\n",
    "                    ngram = curr\n",
    "                    continue\n",
    "                right = {}\n",
    "                freq = 0\n",
    "                for w in sameWord:\n",
    "                    if w.startswith(ngram) == False:\n",
    "                        break\n",
    "                    if w == ngram:\n",
    "                        continue\n",
    "                    freq += 1\n",
    "                    neww = w[:len(ngram)-1]\n",
    "                    right[neww] = right.get(neww, 0) + 1\n",
    "                res= 0.0\n",
    "                for t in right.keys():\n",
    "                    p = right[t] * 1.0 / freq\n",
    "                    res += -1 * p * math.log(p)\n",
    "                print(ngram,freq,res)\n",
    "                newlist = []\n",
    "                for w in sameWord:\n",
    "                    if w != ngram:\n",
    "                        newlist.append(w)\n",
    "                sameWord = newlist\n",
    "                if not sameWord:\n",
    "                    pause = False\n",
    "                    sameWord.append(curr)\n",
    "                    ngram = curr\n",
    "                    continue\n",
    "                ngram = sameWord[0]\n",
    "                if curr.startswith(ngram):\n",
    "                    sameWord.append(curr)\n",
    "                else:\n",
    "                    pause = True\n",
    "getRight(ngramsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$ˊ', '$ˋ', '仔呆阿个一', '的气生够不', '不还爱恋个', '猪出笑真个', '$仔呆阿个', '$ˊ笑好么', '笑好么这么', '$仔', '$悲允', '$声猪出', '笑真个那叫', '啦喜有您后', '$仔呆', '$哈', '$哈', '$哈哈', '$哈哈', '$哈哈哈', '$哈哈哈', '$哈哈哈哈', '$哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '哈哈哈哈哈', '怎哈哈哈哈', '么怎哈哈哈', '这么怎哈哈', '么这么怎哈', '$啦', '$啦喜', '$水池西园', '$声', '$的气生够', '喜有您后太', '您后太皇太', '$ˊ笑好', '个那叫猪学', '好么这么怎', '够不还爱恋', '$啦喜有您', '$悲', '$啦喜有', '$梨', '$的气', '$水', '$水池', '$车防消', '生够不还爱', '真个那叫猪', '$声猪', '$的气生', '$的', '有您后太皇', '声猪出笑真', '$ˊ笑', '$声猪出笑', '$菌', '$水池西', '还爱恋个谈', '$车', '气生够不还', 'ˊ笑好么这', '出笑真个那', '$车防', '$仔呆阿']\n"
     ]
    }
   ],
   "source": [
    "revngramsort = [c[::-1] for c in ngramsort]\n",
    "print(revngramsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLeft(revngramsort):\n",
    "    outpath = \"freqleft.data\"\n",
    "    sys.stdout = open(outpath, 'wt')\n",
    "    ngram = \"\"\n",
    "    pause = False\n",
    "    sameWord = []\n",
    "    for curr in revngramsort:\n",
    "    #     print(\"curr\", curr)\n",
    "        if pause:\n",
    "            break\n",
    "        if ngram == \"\":\n",
    "            sameWord.append(curr)\n",
    "            ngram = curr\n",
    "        else:\n",
    "            if curr.startswith(ngram):\n",
    "                sameWord.append(curr)\n",
    "                pause = False\n",
    "    #             print(\"1\",sameWord)\n",
    "            else:\n",
    "                if not sameWord: # sameword is empty\n",
    "                    pause = False\n",
    "                    sameWord.append(curr)\n",
    "                    ngram = curr\n",
    "                    continue\n",
    "                left = {}\n",
    "                freq = 0\n",
    "                for w in sameWord:\n",
    "                    if w.startswith(ngram) == False:\n",
    "                        break\n",
    "                    if w == ngram:\n",
    "                        continue\n",
    "                    freq += 1\n",
    "                    neww = w[:len(ngram)-1]\n",
    "                    left[neww] = left.get(neww, 0) + 1\n",
    "                res= 0.0\n",
    "                for t in left.keys():\n",
    "                    p = left[t] * 1.0 / freq\n",
    "                    res += -1 * p * math.log(p)\n",
    "                print(ngram,freq,res)\n",
    "                newlist = []\n",
    "                for w in sameWord:\n",
    "                    if w != ngram:\n",
    "                        newlist.append(w)\n",
    "                sameWord = newlist\n",
    "                if not sameWord:\n",
    "                    pause = False\n",
    "                    sameWord.append(curr)\n",
    "                    ngram = curr\n",
    "                    continue\n",
    "                ngram = sameWord[0]\n",
    "                if curr.startswith(ngram):\n",
    "                    sameWord.append(curr)\n",
    "                else:\n",
    "                    pause = True\n",
    "getLeft(revngramsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeEntropy(rightpath, leftpath):\n",
    "    \n",
    "    with open(rightpath, 'r') as rf:\n",
    "        rightline = rf.readlines() \n",
    "    with open(leftpath, 'r') as lf:\n",
    "        leftline = lf.readlines() \n",
    "        \n",
    "    outpath = \"merge.tmp\"\n",
    "    sys.stdout = open(outpath, 'wt')\n",
    "    newlines = rightline + leftline\n",
    "    for line in rightline:\n",
    "        print(line)\n",
    "    for line in leftline:\n",
    "        print(line)\n",
    "        \n",
    "    sortFile(mergetmp, mergetmp2)\n",
    "    \n",
    "    outpath = \"merge_entropy.data\"\n",
    "    sys.stdout = open(outpath, 'wt')\n",
    "    f = open(mergetmp2, 'r')\n",
    "    line1 = \"\"\n",
    "    line2 = \"\"\n",
    "    line1 = f.readline()\n",
    "    line2 = f.readline()\n",
    "    while True:\n",
    "        if line1 == \"\" or line2 == \"\":\n",
    "            break\n",
    "        seg1 = line1.split(\"\\t\")\n",
    "        seg2 = line2.split(\"\\t\")\n",
    "        if seg1[0] != seg2[0]\n",
    "            line1 = line2\n",
    "            line2 = f.readline()\n",
    "            continue\n",
    "        if len(seg1) < 2:\n",
    "            line1 = line2\n",
    "            line2 = f.readline()\n",
    "            continue\n",
    "            \n",
    "        le = float(seg1[1]) if len(seg1) == 2 else float(seg2[1])\n",
    "        re = float(seg1[2]) if len(seg1) == 3 else float(seg2[2])\n",
    "        freq = int(seg1[1]) if len(seg1) == 3 else int(seg2[1])\n",
    "        print(seg1[0],freq, e)\n",
    "        line1 = f.readline()\n",
    "        line2 = f.readline()\n",
    "            \n",
    "        \n",
    "mergeEntropy(\"freqright.data\", \"freqleft.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = False\n",
    "i = 1\n",
    "j = 1\n",
    "j != (t == True)\n",
    "while j != t == True:\n",
    "    if i == 10: \n",
    "        t = True\n",
    "    i += 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWords(freqFile, entropyFile):\n",
    "    with open(freqFile, 'r') as f:\n",
    "        fr = f.readlines() \n",
    "    with open(entropyFile, 'r') as f:\n",
    "        er = f.readlines() \n",
    "    \n",
    "    outpath = \"words.data\"\n",
    "    sys.stdout = open(outpath, 'wt')\n",
    "    \n",
    "    freq = {}\n",
    "    for line in fr:\n",
    "        seg = line.split(\"\\t\")\n",
    "        if len(seg) < 3:\n",
    "            continue\n",
    "        freq[seg[0]] = int(seg[1])\n",
    "    \n",
    "    for line in er:\n",
    "        seg = line.split(\"\\t\")\n",
    "        if len(seg) == 3:\n",
    "            continue\n",
    "        w = seg[0]\n",
    "        f = int(seg[1])\n",
    "        e = float(seg[2])\n",
    "        max = -1\n",
    "        for s in range(1, len(w)):\n",
    "            lw = w[:s]\n",
    "            rw = w[s:]\n",
    "            if lw not in freq.keys() or rw not in freq.keyw():\n",
    "                continue\n",
    "            ff = freq[lw] * freq[rw]\n",
    "            if ff > max:\n",
    "                max = ff\n",
    "        pf = f * 200000.0 / max\n",
    "        if pf < 10 or e < 2:\n",
    "            continue\n",
    "        print(w, pf, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "numeric_const_pattern = \"[-+]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?\"\n",
    "one_str = re.sub(numeric_const_pattern, '', \"-1.7605603\t无 法 从 三\t-0.08918797\")\n",
    "one_str = ''.join(one_str.split())\n",
    "print(one_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'无法从三'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(int(\"34\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
