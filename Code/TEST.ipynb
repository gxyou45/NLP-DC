{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4329293312157919"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(ngram, model=\"k\"):\n",
    "    return random.random()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = \"你們好嗎\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_sentence(ss):\n",
    "    '''\n",
    "    scan the sentence ss with windows of sizes 2, 3, and 4 and get the sentence score respectively\n",
    "    input - ss: the input sentence\n",
    "    '''\n",
    "    hngrams = [] # hierachical ngrams\n",
    "    hscores = [] # hierachical scores\n",
    "    havg_scores = [] # hierachical smoothed scores for each character\n",
    "\n",
    "    for k in [2, 3, 4]:\n",
    "        ngrams = []\n",
    "        scores = []\n",
    "        for i in range(len(ss) - k + 1):\n",
    "            ngram = ss[i:i+k]\n",
    "            ngrams.append(ngram)\n",
    "            score = get_score(ngram, model=\"k\")\n",
    "            scores.append(score)\n",
    "        print(k,\"ngram\",ngrams)\n",
    "        print(k,\"scores\",scores)\n",
    "        hngrams.append(ngrams)\n",
    "        zipped = zip(ngrams, [round(score, 3) for score in scores])\n",
    "        # print(list(zipped))\n",
    "        hscores.append(scores)\n",
    "        #print(k,\"hngrams\",hngrams)\n",
    "        #print(k,\"hscores\",hscores)\n",
    "\n",
    "        # Pad the scores list for moving window average\n",
    "        for _ in range(k-1): \n",
    "            scores.insert(0, scores[0])\n",
    "            scores.append(scores[-1])\n",
    "        print(k, \"pad\", scores)\n",
    "        avg_scores = [sum(scores[i:i+k]) / len(scores[i:i+k]) for i in range(len(ss))]\n",
    "        print(k, \"avg\", avg_scores)\n",
    "        havg_scores.append(avg_scores)\n",
    "        print(k, \"havg\", havg_scores)\n",
    "\n",
    "    # average score for each character in the sentence\n",
    "    per_word_scores = list(np.average(np.array(havg_scores), axis=0)) \n",
    "    print(k, \"per_word_scores\", per_word_scores)\n",
    "\n",
    "    ### [TODO] detect outlier here\n",
    "#     outindices, _ = mad_based_outlier(np.array(list(per_word_scores)), threshold=1.2)\n",
    "#     if outindices:\n",
    "#         outranges = merge_ranges([[outindex, outindex+1] for outindex in outindices])\n",
    "#         print('outranges are {}'.format(outranges))\n",
    "#     else:\n",
    "#         outranges = []\n",
    "#         print('No outranges.')\n",
    "    return per_word_scores, hscores#, outranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ngram ['你們', '們好', '好嗎']\n",
      "2 scores [0.7168402181988845, 0.055807009042811995, 0.8110440378859681]\n",
      "2 pad [0.7168402181988845, 0.7168402181988845, 0.055807009042811995, 0.8110440378859681, 0.8110440378859681]\n",
      "2 avg [0.7168402181988845, 0.38632361362084827, 0.43342552346439006, 0.8110440378859681]\n",
      "2 havg [[0.7168402181988845, 0.38632361362084827, 0.43342552346439006, 0.8110440378859681]]\n",
      "3 ngram ['你們好', '們好嗎']\n",
      "3 scores [0.5792743571704683, 0.15123347380444163]\n",
      "3 pad [0.5792743571704683, 0.5792743571704683, 0.5792743571704683, 0.15123347380444163, 0.15123347380444163, 0.15123347380444163]\n",
      "3 avg [0.5792743571704683, 0.4365940627151261, 0.2939137682597838, 0.15123347380444163]\n",
      "3 havg [[0.7168402181988845, 0.38632361362084827, 0.43342552346439006, 0.8110440378859681], [0.5792743571704683, 0.4365940627151261, 0.2939137682597838, 0.15123347380444163]]\n",
      "4 ngram ['你們好嗎']\n",
      "4 scores [0.4422225525363396]\n",
      "4 pad [0.4422225525363396, 0.4422225525363396, 0.4422225525363396, 0.4422225525363396, 0.4422225525363396, 0.4422225525363396, 0.4422225525363396]\n",
      "4 avg [0.4422225525363396, 0.4422225525363396, 0.4422225525363396, 0.4422225525363396]\n",
      "4 havg [[0.7168402181988845, 0.38632361362084827, 0.43342552346439006, 0.8110440378859681], [0.5792743571704683, 0.4365940627151261, 0.2939137682597838, 0.15123347380444163], [0.4422225525363396, 0.4422225525363396, 0.4422225525363396, 0.4422225525363396]]\n",
      "4 per_word_scores [0.57944570930189743, 0.42171340962410464, 0.38985394808683776, 0.46816668807558309]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.57944570930189743,\n",
       "  0.42171340962410464,\n",
       "  0.38985394808683776,\n",
       "  0.46816668807558309],\n",
       " [[0.7168402181988845,\n",
       "   0.7168402181988845,\n",
       "   0.055807009042811995,\n",
       "   0.8110440378859681,\n",
       "   0.8110440378859681],\n",
       "  [0.5792743571704683,\n",
       "   0.5792743571704683,\n",
       "   0.5792743571704683,\n",
       "   0.15123347380444163,\n",
       "   0.15123347380444163,\n",
       "   0.15123347380444163],\n",
       "  [0.4422225525363396,\n",
       "   0.4422225525363396,\n",
       "   0.4422225525363396,\n",
       "   0.4422225525363396,\n",
       "   0.4422225525363396,\n",
       "   0.4422225525363396,\n",
       "   0.4422225525363396]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_sentence(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p [1 2 3 4]\n",
      "m [ 2.5]\n",
      "d [ 1.5  0.5  0.5  1.5]\n"
     ]
    }
   ],
   "source": [
    "points = [1, 2, 3, 4]\n",
    "points = np.array(points)\n",
    "print(\"p\",points)\n",
    "if len(points.shape) == 1:\n",
    "    points = points[:, None]\n",
    "\n",
    "# get the median of all points\n",
    "median = np.median(points, axis=0) \n",
    "print(\"m\",median)\n",
    "# deviation from the median\n",
    "diff = np.sqrt(np.sum((points - median)**2, axis=-1))\n",
    "print(\"d\",diff)\n",
    "# median absolute deviation\n",
    "med_abs_deviation = np.median(diff) \n",
    "z_score = 0.6745 * diff / med_abs_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_dis(s1, s2):\n",
    "    \n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_edit_dis(\"abc\",\"abdd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
